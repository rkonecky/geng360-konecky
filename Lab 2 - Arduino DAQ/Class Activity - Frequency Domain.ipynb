{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31fce79",
   "metadata": {},
   "source": [
    "# Working in the Frequency Domain\n",
    "Created By: Prof. Hoople for GENG 360\n",
    "\n",
    "This Jupyter notebook is designed to give you some familiarity with how to work with frequency data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As alwayw, we start by importing our libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sounddevice as sd\n",
    "\n",
    "from scipy.signal import welch # We'll need this for power spectral density estimation \n",
    "\n",
    "# Allow for interactive plotting in Jupyter notebooks, comment out to turn this off. \n",
    "# The % sign is a Jupyter magic command that enables the use of widgets in the notebook.\n",
    "# This requires installing the ipympl package.\n",
    "%matplotlib widget \n",
    "\n",
    "# For interactive data point selection in plots, this library is useful.\n",
    "import mplcursors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b880b1",
   "metadata": {},
   "source": [
    "# Flute Data\n",
    "We'll start this activity with some data of a flute playing a note.\n",
    "\n",
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "flute = pd.read_csv(\"data/flute.csv\") # You may need to adjust the path to where your CSV file is located.\n",
    "flute.head() #This will display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d667f9",
   "metadata": {},
   "source": [
    "## Listen to the data\n",
    "Before doing any analysis, let's listen to hear what this data sounds like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae105e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data was sampled at 48,000 Hz, so we set the sampling frequency.\n",
    "fs_flute = 48000\n",
    "\n",
    "# Next we scale the signal from -1 to 1 so we can hear it properly.\n",
    "# This is necessary because the sounddevice library expects audio data to be in this range.\n",
    "flute['Scaled'] = flute['Raw'] / np.max(np.abs(flute['Raw']))\n",
    "sd.play(flute['Scaled'], fs_flute) #Play the scaled flute sound\n",
    "sd.wait() # Wait until the sound has finished playing before proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084530d8",
   "metadata": {},
   "source": [
    "# Plot the data\n",
    "Now let's plot the data in the time domain. Run this section and a plot will appear! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eac11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time vector based on the sampling rate\n",
    "flute['Time (s)'] = np.arange(0, len(flute)/fs_flute, 1/fs_flute)\n",
    "# The arange function has inputs (start, stop, step).\n",
    "\n",
    "# Plot the data\n",
    "plt.figure()  #Create a new figure\n",
    "sns.lineplot(x=\"Time (s)\", y=\"Scaled\", data=flute)\n",
    "plt.title('Flute Signal Time Domain')\n",
    "plt.ylabel(\"Scaled Amplitude\")\n",
    "\n",
    "mplcursors.cursor(hover=False)  # Enable interactive cursor for data point selection\n",
    "# Click anywhere on your data to add a cursor\n",
    "# Right-click to remove a cursor\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae24d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create a zoomed in plot on a very small portion of the time domain signal\n",
    "plt.figure()  #Create a new figure\n",
    "sns.lineplot(x=\"Time (s)\", y=\"Scaled\", marker = \"*\", data=flute)\n",
    "plt.title('Flute Signal Time Domain')\n",
    "plt.ylabel(\"Scaled Amplitude\")\n",
    "\n",
    "mplcursors.cursor(hover=False)  # Enable interactive cursor for data point selection\n",
    "# Click anywhere on your data to add a cursor\n",
    "# Right-click to remove a cursor\n",
    "plt.xlim([3, 3.01])\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c697ed",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Does this data looks like something that you could analyze using the frequency domain? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1df8de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92caa150",
   "metadata": {},
   "source": [
    "Based on the time domain signal, how many peaks would you expect to see in the frequency domain? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3c722",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8804875",
   "metadata": {},
   "source": [
    "What do the stars on the plot represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd1a83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6989f54",
   "metadata": {},
   "source": [
    "## Create a power spectral density plot\n",
    "We'll use Python's welch function to create a power spectral density plot as we discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11069681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definte input parameters for Welch's method\n",
    "segment_size = 4096 # Size of each segment for Welch's method, should be a power of 2 (e.g. 256, 512, 1024, 2048, 4096)\n",
    "overlap_pct = 60 # Percentage of overlap between segments, typically 25-75%\n",
    "overlap_size = int(segment_size * overlap_pct / 100) # Calculate the number of samples to overlap between segments\n",
    "\n",
    "# Compute Power Spectral Density using Welch's method\n",
    "f, pxx = welch(flute['Scaled'], fs=fs_flute, window=\"hann\", nperseg=segment_size, noverlap=overlap_size)\n",
    "\n",
    "# f is the frequency vector, pxx is the power spectral density estimate\n",
    "# For more details, see the documentation https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x=f, y=pxx, marker = '*')\n",
    "plt.xscale('log')  # Logarithmic scale for frequency axis\n",
    "plt.yscale('log')  # Logarithmic scale for power spectral density\n",
    "plt.xlim([20, 20000])  # Limit x-axis to typical audio frequency range\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD Amplitude (Arbitrary Units)')\n",
    "plt.title('Flute Signal Power Spectral Density')\n",
    "plt.grid(True)\n",
    "mplcursors.cursor(hover=False)  # Enable interactive cursor for data point selection\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fa57f",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Adjust the segment size in the code and genereate the plot several times. What differences do you observe when you use the smallest segment size vs. the biggest? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720fa9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6f69f6",
   "metadata": {},
   "source": [
    "Why wouldn't you always want to use the largest segment size? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd136e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13f652d",
   "metadata": {},
   "source": [
    "Choose your segment size as 4096. Add a tag to the highest peak. What note & octave does that correspond to from a flute? See https://mixbutton.com/music-tools/frequency-and-pitch/music-note-to-frequency-chart#1st. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082be2a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48f29129",
   "metadata": {},
   "source": [
    "# Noisy Data\n",
    "Now let's turn our attention to some \"random\" noise data. Here' you'll have to apply what you learned from above. \n",
    "\n",
    "## Import & Listen\n",
    "Fill in the code below to import the data and play it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = # Add code to import the data\n",
    "print(noise.head())  # Display the first few rows of the DataFrame to see what variables are present. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73faa901",
   "metadata": {},
   "source": [
    "Now fill in the code below to listen to this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs_noise = 1/(noise['Time (s)'].iloc[1] - noise['Time (s)'].iloc[0])  # Calculate the sampling frequency based on the time column\n",
    "\n",
    "sd.play(______Fill_In__________, fs_noise) #Play the scaled noise1\n",
    "sd.wait() # Wait until the sound has finished playing before proceeding\n",
    "sd.play(_____Fill_In___________, fs_noise) #Play the scaled noise2\n",
    "sd.wait() # Wait until the sound has finished playing before proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7b643",
   "metadata": {},
   "source": [
    "## Questions\n",
    "What differences can you hear between the two data sets?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ecae3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c576abd",
   "metadata": {},
   "source": [
    "\n",
    "## Time Domain Plot\n",
    "Now let's create a time domain plot. Fill in the code below to plot the two data sets using subplots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34764f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(6, 4), sharex=True, sharey=True)\n",
    "\n",
    "# Fill in the missing values for the line plots\n",
    "#Noise 1\n",
    "sns.lineplot(x=\"Time (s)\", y=___Fill_In____, data=___Fill_In____, color = \"green\", linestyle=\"-\", ax=ax[0])\n",
    "\n",
    "#Noise 2\n",
    "sns.lineplot(x=\"Time (s)\", y=___Fill_In____, data=___Fill_In____, color = \"blue\", linestyle=\"-\", ax=ax[1])\n",
    "\n",
    "ax[0].set_title(\"Noise 1\")\n",
    "ax[1].set_title(\"Noise 2\")\n",
    "ax[0].set_ylabel(\"Amplitude\")\n",
    "ax[1].set_ylabel(\"Amplitude\")\n",
    "ax[1].set_xlabel(\"Time (s)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab8d11",
   "metadata": {},
   "source": [
    "## Questions \n",
    "Try zooming in using the interactive plot tools. What differences can you see between the signals when plotted in the time domain? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0ce7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29c4151",
   "metadata": {},
   "source": [
    "How does that difference relate to what you can hear? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad0ffd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "587f68dd",
   "metadata": {},
   "source": [
    "## Moving to the Frequency Domain\n",
    "Now let's convert the signals to the frequency domain. Adapt the code above for the flute to create a plot that shows the power spectral density for these two signals on the same axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definte input parameters for Welch's method\n",
    "noise_segment_size = 4096 # Size of each segment for Welch's method, should be a power of 2 (e.g. 256, 512, 1024, 2048, 4096)\n",
    "noise_overlap_pct = 60 # Percentage of overlap between segments, typically 25-75%\n",
    "noise_overlap_size = int(noise_segment_size * noise_overlap_pct / 100) # Calculate the number of samples to overlap between segments\n",
    "\n",
    "\n",
    "# Compute Power Spectral Density using Welch's method\n",
    "f_noise1, pxx_noise1 = __________Fill_In__________\n",
    "f_noise2, pxx_noise2 = __________Fill_In__________\n",
    "\n",
    "plt.figure()\n",
    "sns.lineplot(x=f_noise1, y=pxx_noise1, label='Noise 1')\n",
    "sns.lineplot(x=f_noise2, y=pxx_noise2, label='Noise 2')\n",
    "plt.xscale('log')  # Logarithmic scale for frequency axis\n",
    "plt.yscale('log')  # Logarithmic scale for power spectral density\n",
    "plt.xlim([20, 20000])  # Limit x-axis to typical audio frequency range\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD Amplitude (Arbitrary Units)')\n",
    "plt.title('Noise Signals Power Spectral Density')\n",
    "plt.grid(True)\n",
    "mplcursors.cursor(hover=False)  # Enable interactive cursor for data point selection\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa57d33",
   "metadata": {},
   "source": [
    "## Questions\n",
    "Looking at your frequency domain plot, can you now tell the difference between the two signals? How does this compare to what you heard with your ears?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de4a45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec748d2",
   "metadata": {},
   "source": [
    "One signal is louder than the other (has more power). How can you tell that from the PSD plot? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080007e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9bb491a",
   "metadata": {},
   "source": [
    "# Submit On Canvas\n",
    "Export your notebook as an HTML file and submit on Canvas. (Click the ... at the top of the notebook file and choose export) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
